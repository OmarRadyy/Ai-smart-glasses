import cv2
import time
import os
import queue
import threading
from datetime import datetime
import random
from ultralytics import YOLO
from gtts import gTTS
import numpy as np
import pygame   # Ù„Ø§Ø²Ù… ØªØ«Ø¨ØªÙ‡: pip install pygame

# ================ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ================
MODEL_PATH = "yolov8n.pt"
FRAME_WIDTH, FRAME_HEIGHT = 640, 480
FOCAL_LENGTH = 600
PROCESS_EVERY_N_FRAMES = 3
ANNOUNCE_COOLDOWN = 3.0

translations = {
    "person": "Ø´Ø®Øµ", "car": "Ø³ÙŠØ§Ø±Ø©", "bicycle": "Ø¯Ø±Ø§Ø¬Ø©",
    "chair": "ÙƒØ±Ø³ÙŠ", "dog": "ÙƒÙ„Ø¨", "cat": "Ù‚Ø·Ø©", "table": "Ø·Ø§ÙˆÙ„Ø©","elephant": "ÙÙŠÙ„"
}

real_height = {
    "person": 1.7, "car": 1.5, "bicycle": 1.2, "chair": 1.0,
    "dog": 0.6, "cat": 0.3, "table": 0.8 , "elephant": 0.9
}

# Ø¯ÙŠ ÙˆØ­Ø¯Ù‡ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pygame
def start_audio_worker():
    q = queue.Queue()
    stop_flag = threading.Event()
    pygame.mixer.init()  # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙŠÙƒØ³Ø±

    def worker():
        while not stop_flag.is_set():
            try:
                text = q.get(timeout=0.5)
            except queue.Empty:
                continue

            filename = None
            try:
                # Ø£Ù†Ø´Ø¦ Ù…Ù„Ù Ù…Ø¤Ù‚Øª Ù…Ù† gTTS
                filename = f"voice_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}_{random.randint(0,9999)}.mp3"
                gTTS(text=text, lang='ar').save(filename)

                # Ø´ØºÙ‘Ù„ Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pygame (ØºÙŠØ± Ù…Ø­Ø¸ÙˆØ±)
                try:
                    pygame.mixer.music.load(filename)
                    pygame.mixer.music.play()
                    # Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ Ù†Ø±Ø§Ù‚Ø¨ stop_flag ÙÙ†ÙˆÙ‚Ù ÙÙˆØ±Ù‹Ø§ Ù„Ùˆ Ø§ØªØ·Ù„Ø¨
                    while pygame.mixer.music.get_busy():
                        if stop_flag.is_set():
                            pygame.mixer.music.stop()
                            break
                        time.sleep(0.05)
                except Exception as e:
                    print("âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª (pygame):", e)

            except Exception as e:
                print("âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØª:", e)
            finally:
                # Ø§Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ù„Ùˆ Ø§ØªØ¹Ù…Ù„
                try:
                    if filename and os.path.exists(filename):
                        os.remove(filename)
                except Exception as e:
                    print("âš ï¸ Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ:", e)
                # Ø¯ÙŠ Ø¹Ù„Ø§Ù…Ø© Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØµÙ 
                try:
                    q.task_done()
                except Exception:
                    pass

    t = threading.Thread(target=worker, daemon=True)
    t.start()

    # Ø¯Ø§Ù„Ø© Ù„ÙˆÙ‚Ù Ø§Ù„Ø¹Ø§Ù…Ù„ ÙÙˆØ±Ù‹Ø§ (ØªÙˆÙ‚Ù Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø£ÙŠØ¶Ø§Ù‹)
    def stop():
        stop_flag.set()
        try:
            # ÙˆÙ‚Ù Ø§ÙŠ ØµÙˆØª Ø´ØºØ§Ù„ Ø¯Ù„ÙˆÙ‚ØªÙŠ
            pygame.mixer.music.stop()
        except Exception:
            pass

    return q, stop

#      Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© 
def estimate_distance(obj_name, pixel_height):
    if obj_name not in real_height or pixel_height <= 0:
        return None
    return (real_height[obj_name] * FOCAL_LENGTH) / pixel_height

def detect_direction(x_center, frame_width):
    if x_center < frame_width / 3:
        return "Ø¹Ù„Ù‰ Ø§Ù„ÙŠØ³Ø§Ø±"
    elif x_center > (2 * frame_width) / 3:
        return "Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙ…ÙŠÙ†"
    return "Ø£Ù…Ø§Ù…Ùƒ"

def make_message(name, direction, distance):
    d = round(distance, 1)
    if distance < 0.5:
        return f"{translations[name]} {direction} Ø¹Ù„Ù‰ Ø¨Ø¹Ø¯ Ù†ØµÙ Ù…ØªØ±! Ø§Ø­Ø°Ø±!"
    elif distance < 1.0:
        return f"{translations[name]} {direction} Ø¹Ù„Ù‰ Ø¨Ø¹Ø¯ Ù…ØªØ± ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§!"
    else:
        return f"{translations[name]} {direction} Ø¹Ù„Ù‰ Ø¨Ø¹Ø¯ {d} Ù…ØªØ±"

# Ø§Ù„ÙØ§Ù†ÙƒØ´Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø¨Ù‚ÙŠ 
def main():
    model = YOLO(MODEL_PATH)
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ Ù„Ù… ÙŠØªÙ… ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")
        return

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

    audio_q, stop_audio = start_audio_worker()
    last_time = {}
    frame_count = 0

    print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹Ù…Ù„... Ø§Ø¶ØºØ· Q Ø£Ùˆ ESC Ù„Ù„Ø®Ø±ÙˆØ¬ (Ø§Ù„ØµÙˆØª Ø³ÙŠØªÙˆÙ‚Ù ÙÙˆØ±Ù‹Ø§)")

    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            # Ù†Ø¹Ø±Ø¶ Ø¨Ø¯ÙˆÙ† ØªØ­Ù„ÙŠÙ„ Ù„Ø¨Ø¹Ø¶ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù„ØªØ®ÙÙŠÙ Ø§Ù„Ø­Ù…Ù„
            if frame_count % PROCESS_EVERY_N_FRAMES != 0:
                cv2.imshow("Smart Glasses", frame)
                key = cv2.waitKey(1) & 0xFF
                if key in [ord('q'), 27]:
                    print("â¹ï¸ ØªÙ… Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Q/ESC - Ø¥ØºÙ„Ø§Ù‚...")
                    break
                continue

            results = model(frame)
            annotated = results[0].plot()
            width = frame.shape[1]
            now = time.time()

            boxes = results[0].boxes.xyxy.cpu().numpy() if hasattr(results[0].boxes.xyxy, "cpu") else np.array(results[0].boxes.xyxy)
            classes = results[0].boxes.cls.cpu().numpy() if hasattr(results[0].boxes.cls, "cpu") else np.array(results[0].boxes.cls)

            for box, cls in zip(boxes, classes):
                name = results[0].names[int(cls)]
                if name not in translations:
                    continue

                x1, y1, x2, y2 = box
                distance = estimate_distance(name, abs(y2 - y1))
                if not distance or distance > 4.0:
                    continue

                direction = detect_direction((x1 + x2) / 2, width)
                if now - last_time.get(name, 0) < ANNOUNCE_COOLDOWN:
                    continue
                last_time[name] = now

                msg = make_message(name, direction, distance)
                print("ğŸ”Š", msg)
                try:
                    audio_q.put_nowait(msg)
                except queue.Full:
                    pass

            cv2.imshow("Smart Glasses", annotated)
            key = cv2.waitKey(1) & 0xFF
            if key in [ord('q'), 27]:
                print("â¹ï¸ ØªÙ… Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Q/ESC - Ø¥ØºÙ„Ø§Ù‚...")
                break

    finally:
        # ÙˆÙ‚Ù Ø§Ù„Ø¹Ø§Ù…Ù„ (Ù‡ÙŠÙˆÙ‚Ù Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ù‰ ÙÙˆØ±Ù‹Ø§)
        stop_audio()
        # Ù†ÙØ¶ Ø§Ù„ØµÙ Ù„ÙƒÙ† Ù…Ù† ØºÙŠØ± Ø§Ù†ØªØ¸Ø§Ø± ØµÙˆØª ÙŠØ®Ù„Øµ Ù„Ø£Ù† Ø¥Ø­Ù†Ø§ Ø¨Ù†ÙˆÙ‚ÙÙ‡ ÙØ¹Ù„ÙŠÙ‹Ø§
        try:
            while not audio_q.empty():
                audio_q.get_nowait()
                audio_q.task_done()
        except Exception:
            pass

        cap.release()
        cv2.destroyAllWindows()
        print("ğŸ”´ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ´ØºÙŠÙ„")

if __name__ == "__main__":
    main()
